{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4690a730",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "from fnope.simulators.darcy import Darcy2D\n",
    "from fnope.flow_matching.fnope_2D import FNOPE_2D\n",
    "\n",
    "\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "from torch.optim import Adam\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "torch.manual_seed(0)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2b5bee6",
   "metadata": {},
   "source": [
    "## Darcy Simulator\n",
    "\n",
    "In this tutorial we use the darcy flow problem to showcase FNOPE (fix) for parameters\n",
    "varying in 2 dimensions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83c4c318",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "prior_params_darcy = {\"tau\": 9.0,\"alpha\":2.0,\"scale\":1000.0}\n",
    "\n",
    "batch_size = 256 #simulation batch size\n",
    "resolution = 64 #smaller than reported experiment so this notebook can be run faster\n",
    "theta_x_size = resolution+1\n",
    "theta_y_size = resolution+1\n",
    "\n",
    "darcy = Darcy2D(prior = \"Darcy_GP\",   prior_params_darcy=prior_params_darcy, snr=30.0,batch_size=batch_size, resolution=resolution)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2bc76383",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_sim = 1000 #num training_sims\n",
    "\n",
    "n_full_batches = n_sim // batch_size\n",
    "last_batch_size = n_sim % batch_size\n",
    "\n",
    "all_theta = []\n",
    "all_x = []\n",
    "\n",
    "# Generate all batches and collect\n",
    "for i in range(n_full_batches):\n",
    "    theta_temp, theta_res, x_temp = darcy.sample_darcy()\n",
    "    all_x.append(x_temp.cpu())\n",
    "    all_theta.append(theta_temp.cpu()) # theta is the parameter on the grid we sample the prior from.\n",
    "    print(f\"batch {i+1}/{n_full_batches} done.\")\n",
    "\n",
    "if last_batch_size > 0:\n",
    "    # Generate last batch\n",
    "    theta_temp, theta_res, x_temp = darcy.sample_darcy()\n",
    "    all_x.append(x_temp.cpu()[:last_batch_size])\n",
    "    all_theta.append(theta_temp.cpu()[:last_batch_size])\n",
    "\n",
    "# Concatenate all\n",
    "sim_theta = torch.cat(all_theta, dim=0)\n",
    "sim_x = torch.cat(all_x, dim=0)\n",
    "\n",
    "theta_o, theta_res_o,x_temp_o = darcy.sample_darcy()\n",
    "theta_o = theta_o[:10]\n",
    "x_o = x_temp_o[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b817e16d",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"sim_theta contains NaNs:\", torch.isnan(sim_theta).any().item())\n",
    "print(\"sim_x contains NaNs:\", torch.isnan(sim_x).any().item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4728f09a",
   "metadata": {},
   "outputs": [],
   "source": [
    "sim_theta = sim_theta.view(-1,1,theta_x_size,theta_y_size).to(device)\n",
    "sim_x = sim_x.view(-1,1,theta_x_size,theta_y_size).to(device)\n",
    "theta_o = theta_o.view(-1,1,theta_x_size,theta_y_size).to(device)\n",
    "x_o = x_o.view(-1,1,theta_x_size,theta_y_size).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd6e2e82",
   "metadata": {},
   "outputs": [],
   "source": [
    "modes_max = 16 #number of modes used by FNO blocks\n",
    "\n",
    "\n",
    "model = FNOPE_2D(\n",
    "    x = sim_theta, #note: x in `FMPE_Unified` is the parameter (theta), `ctx` is the observation\n",
    "    ctx=sim_x,\n",
    "    simulation_grid=None, #In this example we always evaluate on the same discretization to demonstrate FNOPE (fix)\n",
    "    x_finite=None, #vector-valued parameters (\"finite\")\n",
    "    modes= modes_max, \n",
    "    conv_channels = 16,\n",
    "    ctx_embedding_channels=16,\n",
    "    time_embedding_channels=4,\n",
    "    position_embedding_channels=4,\n",
    "    num_layers=5,\n",
    "    base_dist='gp', #This is the type of distribution used as the base distribution for flow matching. We use a Gaussian Process (the lengthscale is set depending on `modes`).\n",
    "    padding = {\"type\":\"zero\",\"pad_length\":10}, #when using FFT, padding is helpful to avoid artefacts.\n",
    "    always_equispaced=True, # Set to True for FNOPE (fix) - always evaluating on the same grid as the training data\n",
    "    always_match_x_theta=True, #If always_equispaced=True, can also specify whether parameters and observations are defined on the same grid.\n",
    ").to(device)\n",
    "\n",
    "\n",
    "\n",
    "total_params = sum(p.numel() for p in model.parameters())\n",
    "print(f\"Number of parameters: {total_params}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfcd9d27",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_batch_size = 256\n",
    "learning_rate = 1e-3\n",
    "\n",
    "\n",
    "#Set up custom training here, training function also at fnope.flow_matching.training.py::train_fnope\n",
    "dataset = TensorDataset(sim_theta, sim_x)\n",
    "dataloader = DataLoader(dataset, batch_size=batch_size, shuffle=True, drop_last=False)\n",
    "\n",
    "optimizer = Adam(model.parameters(), lr=learning_rate)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3659c0e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.train()\n",
    "num_epochs = 200\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    avg_loss = 0.0\n",
    "    for theta_batch,x_batch in dataloader:\n",
    "        optimizer.zero_grad()\n",
    "        loss = model.loss(theta_batch, ctx=x_batch)\n",
    "        avg_loss += loss.item()*theta_batch.shape[0]/len(dataloader.dataset)\n",
    "\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    print(f\"Epoch {epoch}, total loss: {avg_loss:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f4cc1fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.eval();\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1064854c",
   "metadata": {},
   "source": [
    "## Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32fec93b",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_samples = 100\n",
    "\n",
    "fnope_samples = torch.zeros(num_samples,10,theta_x_size,theta_y_size).to(device)\n",
    "\n",
    "for true_idx in range(10):\n",
    "    print(f\"Sampling for observation no. {true_idx}\")\n",
    "    func_samples= model.sample(num_samples, x_o[true_idx].view(-1,theta_x_size,theta_y_size),atol=1e-2, rtol=1e-2)\n",
    "    fnope_samples[:,true_idx,:] = func_samples.view(num_samples,theta_x_size,theta_y_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25bdd129",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Posterior predictive\n",
    "\n",
    "#simulator object with matching batch size to number of posterior samples\n",
    "darcy_predictive_check = Darcy2D(\n",
    "            batch_size=num_samples,\n",
    "            resolution=resolution,\n",
    "            snr=30.0,\n",
    "        )\n",
    "\n",
    "true_idx = 0\n",
    "t_temp,t_res_temp,fnope_predictive_samples = darcy_predictive_check.simulate_darcy(\n",
    "    fnope_samples[:, true_idx, :, :],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20712b1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "view = (slice(None), slice(None))\n",
    "show_exp = False #show permeability or log-permeability\n",
    "sample_idx = 1 #which sample to show\n",
    "\n",
    "if show_exp:\n",
    "    vmin = 0\n",
    "    vmax = max(fnope_samples[sample_idx,0, *view].exp().max(), theta_o[true_idx,0, *view].exp().max())\n",
    "else:\n",
    "    vmin = None\n",
    "    vmax = None\n",
    "\n",
    "fig,ax = plt.subplots(1, 4, figsize=(16, 5))\n",
    "\n",
    "\n",
    "if show_exp:\n",
    "    colors = ax[0].imshow(theta_o[true_idx,0, *view].exp().detach().cpu().numpy(),vmin=vmin, vmax=vmax)\n",
    "else:\n",
    "    colors = ax[0].imshow(theta_o[true_idx,0,*view].detach().cpu().numpy(),vmin=vmin, vmax=vmax)\n",
    "ax[0].set_title(\"True theta\")\n",
    "\n",
    "if show_exp:\n",
    "    colors2 = ax[1].imshow(fnope_samples[sample_idx,true_idx, *view].exp().detach().cpu().numpy(),vmin=vmin, vmax=vmax)\n",
    "else:\n",
    "    colors2 = ax[1].imshow(fnope_samples[sample_idx,true_idx, *view].detach().cpu().numpy(),vmin=vmin, vmax=vmax)\n",
    "\n",
    "\n",
    "if show_exp:\n",
    "    colors3 = ax[2].imshow(torch.abs(fnope_samples[:,true_idx].exp().mean(dim=0)[view]-theta_o[true_idx,0,*view].exp()).detach().cpu().numpy())\n",
    "else:\n",
    "    colors3 = ax[2].imshow(torch.abs(fnope_samples[:,true_idx].mean(dim=0)[view]-theta_o[true_idx,0,*view]).detach().cpu().numpy())\n",
    "\n",
    "ax[2].set_title(\"Abs error of mean\")\n",
    "\n",
    "if show_exp:\n",
    "    colors4 = ax[3].imshow(fnope_samples[:,true_idx].exp().std(0)[*view].detach().cpu().numpy())\n",
    "else:\n",
    "    colors4 = ax[3].imshow(fnope_samples[:,true_idx].std(0)[view].detach().cpu().numpy())\n",
    "\n",
    "\n",
    "ax[1].set_title(\"FNOPE\")\n",
    "ax[3].set_title(\"FNOPE std\")\n",
    "plt.colorbar(colors,ax=ax[0])\n",
    "plt.colorbar(colors2,ax=ax[1])\n",
    "plt.colorbar(colors3,ax=ax[2])\n",
    "plt.colorbar(colors4,ax=ax[3])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba017a69",
   "metadata": {},
   "outputs": [],
   "source": [
    "view = (slice(None), slice(None))\n",
    "sample_idx = 1 #which sample to show\n",
    "\n",
    "vmin = None\n",
    "vmax = None\n",
    "\n",
    "fig,ax = plt.subplots(1, 4, figsize=(16, 5))\n",
    "\n",
    "\n",
    "colors = ax[0].imshow(x_o[true_idx,0,*view].detach().cpu().numpy(),vmin=vmin, vmax=vmax)\n",
    "ax[0].set_title(\"True x\")\n",
    "\n",
    "colors2 = ax[1].imshow(fnope_predictive_samples[sample_idx, *view].detach().cpu().numpy(),vmin=vmin, vmax=vmax)\n",
    "\n",
    "\n",
    "colors3 = ax[2].imshow(torch.abs(fnope_predictive_samples.mean(dim=0)[view]-x_o[true_idx,0,*view]).detach().cpu().numpy())\n",
    "\n",
    "ax[2].set_title(\"Abs error of mean\")\n",
    "\n",
    "colors4 = ax[3].imshow(fnope_predictive_samples.std(0)[view].detach().cpu().numpy())\n",
    "\n",
    "\n",
    "ax[1].set_title(\"FNOPE predictive\")\n",
    "ax[3].set_title(\"FNOPE predictive std\")\n",
    "plt.colorbar(colors,ax=ax[0])\n",
    "plt.colorbar(colors2,ax=ax[1])\n",
    "plt.colorbar(colors3,ax=ax[2])\n",
    "plt.colorbar(colors4,ax=ax[3])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e68c00d9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "fnope",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
